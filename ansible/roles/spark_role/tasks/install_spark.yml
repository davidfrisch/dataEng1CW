---

- name: Set Spark variable directory
  set_fact:
    spark_install_dir: "{{ spark_install_dir }}"

- name: Verify if spark is already installed
  stat:
    path: "{{ spark_install_dir }}"
  register: spark_installation

- name: Log spark installation status
  debug:
    msg: "Spark is already installed, skipping installation"
  when: spark_installation.stat.exists == True

- name: Download Spark
  get_url:
    url: "{{ spark_download_url }}"
    dest: "/mnt/data/spark-3.5.0-bin-hadoop3.tgz"
    mode: 0755
    validate_certs: no
  register: spark_download
  when: spark_installation.stat.exists == False

- name: Extract Spark
  unarchive:
    src: "{{ spark_download.dest }}"
    dest: "/mnt/data/"
    remote_src: yes
    creates: "/mnt/data/spark-3.5.0-bin-hadoop3"
  when: spark_installation.stat.exists == False

- name: Remove Spark tarball if it exists
  file:
    path: "{{ spark_download.dest }}"
    state: absent
  when: spark_installation.stat.exists == False
  

- name: Move Spark to /opt
  command: mv /mnt/data/spark-3.5.0-bin-hadoop3 {{ spark_install_dir }}
  when: spark_installation.stat.exists == False

# To check because it's not working
- name: Set Spark environment variables in ~/.bashrc
  lineinfile:
    dest: ~/.bashrc
    line: "{{ item }}"
    state: present
  with_items:
    - "export SPARK_HOME={{ spark_install_dir }}"
    - "export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin"
  when: spark_installation.stat.exists == False

- name: Source ~/.bashrc
  shell: source ~/.bashrc

- name: Check Spark version
  command: "{{ spark_install_dir }}/bin/spark-shell --version"
  register: spark_version

- name: Print Spark version
  debug:
    msg: "{{ spark_version.stdout }}"

